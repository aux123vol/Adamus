# START BUILDING ADAMUS NOW
## Complete Setup Guide (Tonight: 8pm-10pm, 2 hours)

**What You're Building**: Adamus (ONE orchestrator with memory) that uses multiple AI tools (OpenClaw, Claude Code)

**What Happens**: Works autonomously 5pm-8am (15 hours) while you're at job/sleep

**Cost**: $12-212/month depending on options

---

## STEP 1: Download Architecture (2 minutes)

```bash
# 1. Download adamus_architecture_v1.tar.gz (â†‘ above)

# 2. Extract
tar -xzf adamus_architecture_v1.tar.gz

# 3. Move to project location
mkdir -p ~/adamus/docs
mv adamus_systems ~/adamus/docs/architecture

# 4. Verify
ls ~/adamus/docs/architecture/
# Should see all 76 .md files

# âœ… DONE: All architecture docs ready
```

---

## STEP 2: Setup Memory System (20 minutes)

### Why This Matters
- 76 docs = 500K+ tokens
- AI context = 64K-200K tokens max
- **Without memory**: Forgets things, rebuilds duplicates
- **With memory**: Perfect recall forever

### Install PostgreSQL + pgvector

```bash
# Mac:
brew install postgresql@14
brew services start postgresql@14

# OR Ubuntu/Linux:
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql

# Install pgvector extension
# Mac:
brew install pgvector

# Ubuntu:
sudo apt install postgresql-14-pgvector

# âœ… Postgres running
```

### Create Database

```bash
# Create database
createdb adamus_memory

# Enable vector extension
psql adamus_memory << 'EOF'
CREATE EXTENSION vector;

-- Document chunks table
CREATE TABLE document_chunks (
    id SERIAL PRIMARY KEY,
    doc_name TEXT,
    chunk_id INTEGER,
    content TEXT,
    embedding VECTOR(1536),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Fast similarity search index
CREATE INDEX ON document_chunks 
USING ivfflat (embedding vector_cosine_ops);

-- Task backlog
CREATE TABLE task_backlog (
    id SERIAL PRIMARY KEY,
    description TEXT,
    priority INTEGER,
    status TEXT,
    dependencies INTEGER[],
    assigned_to TEXT,
    created_at TIMESTAMP,
    completed_at TIMESTAMP
);

-- Capabilities registry
CREATE TABLE capabilities (
    id SERIAL PRIMARY KEY,
    name TEXT,
    description TEXT,
    implemented BOOLEAN,
    location TEXT,
    created_at TIMESTAMP
);

-- Completed tasks (permanent record)
CREATE TABLE completed_tasks (
    id SERIAL PRIMARY KEY,
    task_id INTEGER,
    description TEXT,
    result JSONB,
    files_created TEXT[],
    completed_at TIMESTAMP
);
EOF

# âœ… Database schema created
```

### Install Python Dependencies

```bash
cd ~/adamus

cat > requirements.txt << 'EOF'
# Core
anthropic==0.18.1
openai==1.12.0

# Database
psycopg2-binary==2.9.9
pgvector==0.2.4

# Web
flask==3.0.0
requests==2.31.0

# Utilities
beautifulsoup4==4.12.2
feedparser==6.0.10
python-dotenv==1.0.0
EOF

pip3 install -r requirements.txt

# âœ… Dependencies installed
```

### Create Memory System Code

```bash
cd ~/adamus
mkdir -p src/memory

# Create persistent memory system
cat > src/memory/persistent_memory.py << 'PYTHON'
import os
import openai
import psycopg2
from pgvector.psycopg2 import register_vector
from glob import glob
from typing import List, Dict

class PersistentMemorySystem:
    """Adamus's permanent memory - never forgets"""
    
    def __init__(self):
        self.conn = psycopg2.connect(
            dbname='adamus_memory',
            user=os.getenv('USER'),
            host='localhost'
        )
        register_vector(self.conn)
        self.openai = openai.Client(api_key=os.getenv('OPENAI_API_KEY'))
        
    def embed_text(self, text: str) -> List[float]:
        """Create embedding for text"""
        response = self.openai.embeddings.create(
            model='text-embedding-3-small',
            input=text
        )
        return response.data[0].embedding
        
    def ingest_documents(self, docs_path: str):
        """Read all 76 docs and store in vector DB"""
        print("ðŸ“š Ingesting architecture documents...")
        
        doc_files = glob(f"{docs_path}/**/*.md", recursive=True)
        total_chunks = 0
        
        for doc_file in doc_files:
            print(f"â³ Processing {os.path.basename(doc_file)}...")
            
            with open(doc_file, 'r') as f:
                content = f.read()
                
            # Chunk into 500-token pieces
            chunks = self.chunk_text(content, chunk_size=500)
            
            for i, chunk in enumerate(chunks):
                # Create embedding
                embedding = self.embed_text(chunk)
                
                # Store in database
                with self.conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO document_chunks 
                        (doc_name, chunk_id, content, embedding)
                        VALUES (%s, %s, %s, %s)
                    """, (doc_file, i, chunk, embedding))
                    
                total_chunks += 1
                
            self.conn.commit()
            print(f"âœ… {os.path.basename(doc_file)}")
            
        print(f"\nâœ… All documents ingested!")
        print(f"ðŸ“Š Total chunks: {total_chunks}")
        print("ðŸ” Memory system ready\n")
        
    def chunk_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """Split text into chunks"""
        words = text.split()
        chunks = []
        current_chunk = []
        current_size = 0
        
        for word in words:
            current_chunk.append(word)
            current_size += 1
            
            if current_size >= chunk_size:
                chunks.append(' '.join(current_chunk))
                current_chunk = []
                current_size = 0
                
        if current_chunk:
            chunks.append(' '.join(current_chunk))
            
        return chunks
        
    def search(self, query: str, limit: int = 20) -> List[Dict]:
        """Find relevant doc chunks for query"""
        # Create query embedding
        query_embedding = self.embed_text(query)
        
        # Search vector DB
        with self.conn.cursor() as cur:
            cur.execute("""
                SELECT doc_name, content, 
                       embedding <=> %s::vector AS distance
                FROM document_chunks
                ORDER BY distance
                LIMIT %s
            """, (query_embedding, limit))
            
            results = []
            for row in cur.fetchall():
                results.append({
                    'doc': row[0],
                    'content': row[1],
                    'relevance': 1 - row[2]
                })
                
        return results

if __name__ == '__main__':
    memory = PersistentMemorySystem()
    memory.ingest_documents('/Users/YOUR_USERNAME/adamus/docs/architecture')
PYTHON

# âœ… Memory system code created
```

### Ingest All 76 Documents

```bash
cd ~/adamus

# Set OpenAI API key (for embeddings)
export OPENAI_API_KEY="your-key-here"

# Run ingestion
python3 src/memory/persistent_memory.py

# Output:
# ðŸ“š Ingesting architecture documents...
# â³ Processing NETWORKED_AI_TRINITY.md...
# âœ… NETWORKED_AI_TRINITY.md
# â³ Processing DATA_GOVERNANCE_FRAMEWORK.md...
# âœ… DATA_GOVERNANCE_FRAMEWORK.md
# ... (74 more)
# 
# âœ… All documents ingested!
# ðŸ“Š Total chunks: 2,847
# ðŸ” Memory system ready

# Takes 5 minutes
# Costs $0.01 (one cent for embeddings)

# âœ… DONE: Adamus now has permanent memory
```

---

## STEP 3: Install OpenClaw (15 minutes)

```bash
# Install Node 22+ if needed
node --version  # Should be 22+

# Install OpenClaw
npx openclaw@latest init

# Follow interactive setup:
# 1. Choose messaging platform: Telegram (recommended)
# 2. Connect your Telegram account
# 3. Choose model: Claude Sonnet (or your preference)
# 4. Set API key: Your Anthropic API key

# Test it works
# Send via Telegram: "Hi, who are you?"
# Should respond: "I'm your OpenClaw agent..."

# âœ… OpenClaw installed and working
```

---

## STEP 4: Configure Autonomous Schedule (10 minutes)

```bash
# Configure OpenClaw for your schedule
cat > ~/.openclaw/config.yaml << 'EOF'
# Autonomous mode configuration
autonomous_mode:
  enabled: true
  
  # Your schedule: 5pm-8am (at job + sleeping)
  schedule:
    active_hours: "17:00-08:00"  # 5pm-8am
    timezone: "America/New_York"  # Change to your timezone
    
  # Where to find architecture docs
  docs_path: "~/adamus/docs/architecture/"
  
  # Notifications
  notifications:
    heartbeat:
      interval: "2 hours"
      active_hours: "17:00-02:00"  # During job only
      
    silent_hours: "02:00-08:00"  # During sleep
    
    critical_always:
      - security_breach
      - production_down
      - budget_exceeded

# Security settings
security:
  approval_required:
    - delete_files
    - system_commands
    - production_deploy
    - spend_money
    
  auto_approve:
    - read_files
    - write_to_src
    - run_tests
    - commit_to_git
    - create_pr
    
  sandbox:
    enabled: true
    allowed_paths:
      - "~/adamus/src/"
      - "~/adamus/docs/"
      - "~/genre-repos/"
    denied_paths:
      - "~/.ssh/"
      - "~/.env"
      - "/credentials/"

# GitHub integration
github:
  auto_pr: true
  pr_draft: true  # Always draft until you review
  branch_prefix: "openclaw/"
  require_tests: true
EOF

# âœ… Schedule configured
```

---

## STEP 5: Create Adamus Coordinator (20 minutes)

```bash
cd ~/adamus
mkdir -p src/coordinator

# Create main coordinator
cat > src/coordinator/adamus.py << 'PYTHON'
import os
from datetime import datetime
from memory.persistent_memory import PersistentMemorySystem

class Adamus:
    """
    The ONE orchestrator that coordinates everything
    Uses multiple AI tools but maintains single identity
    """
    
    def __init__(self):
        # Permanent memory
        self.memory = PersistentMemorySystem()
        
        # Available tools (brains)
        self.tools = {
            'openclaw': self.openclaw_available(),
            'claude_code': self.claude_code_available()
        }
        
        print("ðŸ§  Adamus initialized")
        print(f"ðŸ“š Memory: Connected")
        print(f"ðŸ”§ Tools: {', '.join([k for k,v in self.tools.items() if v])}")
        
    def choose_tool(self, task: dict) -> str:
        """Decide which tool to use for this task"""
        # You're working: Use Claude Code
        if self.is_work_hours():
            return 'claude_code'
        # You're offline: Use OpenClaw
        else:
            return 'openclaw'
            
    def is_work_hours(self) -> bool:
        """Check if Augustus is working (8am-5pm)"""
        hour = datetime.now().hour
        return 8 <= hour < 17
        
    def is_autonomous_hours(self) -> bool:
        """Check if autonomous mode (5pm-8am)"""
        hour = datetime.now().hour
        return hour >= 17 or hour < 8
        
    def execute_task(self, task: dict):
        """Execute task with appropriate tool"""
        # Get relevant context from memory
        context = self.memory.search(task['description'])
        
        # Choose tool
        tool = self.choose_tool(task)
        
        print(f"ðŸŽ¯ Task: {task['description']}")
        print(f"ðŸ”§ Using: {tool}")
        print(f"ðŸ“ Context: {len(context)} relevant chunks loaded")
        
        # Execute (implementation depends on tool)
        if tool == 'openclaw':
            return self.execute_with_openclaw(task, context)
        else:
            return self.execute_with_claude_code(task, context)
            
    def openclaw_available(self) -> bool:
        """Check if OpenClaw installed"""
        return os.path.exists(os.path.expanduser('~/.openclaw'))
        
    def claude_code_available(self) -> bool:
        """Check if Claude Code available"""
        return os.path.exists('/usr/local/bin/claude')

if __name__ == '__main__':
    adamus = Adamus()
    
    # Test memory
    results = adamus.memory.search("data governance")
    print(f"\nðŸ” Memory test: Found {len(results)} relevant chunks")
    print(f"ðŸ“„ Top result: {results[0]['doc'] if results else 'None'}")
PYTHON

# Test Adamus
python3 src/coordinator/adamus.py

# Should see:
# ðŸ§  Adamus initialized
# ðŸ“š Memory: Connected
# ðŸ”§ Tools: openclaw, claude_code
# ðŸ” Memory test: Found 20 relevant chunks
# ðŸ“„ Top result: DATA_GOVERNANCE_FRAMEWORK.md

# âœ… Adamus coordinator working
```

---

## STEP 6: Start OpenClaw Daemon (5 minutes)

```bash
# Start OpenClaw as background service
openclaw gateway --install-daemon

# Check status
openclaw status

# Should see:
# âœ… Gateway running
# âœ… Autonomous mode enabled
# âœ… Active hours: 17:00-08:00
# â° Next activation: 5:00 PM today

# âœ… OpenClaw daemon running
```

---

## STEP 7: Give First Autonomous Task (5 minutes)

```bash
# Send via Telegram to your OpenClaw:

"Read all architecture documents in ~/adamus/docs/architecture/ 
and create a prioritized backlog of capabilities to implement.

Start with:
1. List all TODO items
2. List all 'Implementation:' sections
3. Identify dependencies
4. Prioritize: CRITICAL > security > foundation > features

Save the backlog to ~/adamus/data/backlog.json

Report back with the top 10 priorities."

# OpenClaw will:
# 1. Read all 76 docs (using your memory system)
# 2. Extract requirements
# 3. Create backlog
# 4. Prioritize
# 5. Report top 10

# This tests:
# âœ… OpenClaw reads docs
# âœ… Memory system works
# âœ… File creation works
# âœ… Telegram communication works
```

---

## STEP 8: Verify Everything Works (10 minutes)

### Test 1: Memory System

```bash
cd ~/adamus

python3 << 'PYTHON'
from src.memory.persistent_memory import PersistentMemorySystem

memory = PersistentMemorySystem()

# Search for different topics
tests = [
    "data governance",
    "security systems",
    "self-improving",
    "OpenClaw autonomous"
]

for query in tests:
    results = memory.search(query, limit=3)
    print(f"\nðŸ” Query: {query}")
    print(f"ðŸ“Š Results: {len(results)}")
    if results:
        print(f"ðŸ“„ Top doc: {results[0]['doc'].split('/')[-1]}")
PYTHON

# Should see relevant results for each query
# âœ… Memory working
```

### Test 2: OpenClaw Communication

```bash
# Send via Telegram:
"Status check - are you ready for autonomous work tonight?"

# Should respond with:
# "Yes, I'm ready. Autonomous mode activates at 5:00 PM.
#  I have access to 76 architecture documents and memory system.
#  Waiting for your first task."

# âœ… Communication working
```

### Test 3: Schedule Check

```bash
openclaw status

# Should show:
# âœ… Gateway: Running
# âœ… Autonomous: Enabled
# â° Active hours: 17:00-08:00 (5pm-8am)
# ðŸ“… Next activation: Today at 5:00 PM
# â¸ï¸  Current status: Paused (work hours 8am-5pm)

# âœ… Schedule correct
```

---

## STEP 9: Setup Complete Checklist

```yaml
verify_these:
  - âœ… architecture_docs: "All 76 docs in ~/adamus/docs/architecture/"
  - âœ… postgres_running: "Database adamus_memory exists"
  - âœ… memory_ingested: "2,847 chunks stored"
  - âœ… openclaw_installed: "Gateway running as daemon"
  - âœ… schedule_configured: "17:00-08:00 autonomous hours"
  - âœ… telegram_connected: "Can message OpenClaw"
  - âœ… adamus_initialized: "Coordinator working"
  - âœ… memory_tested: "Search returns relevant results"
  
if_all_checked: "âœ… READY FOR AUTONOMOUS OPERATION"
```

---

## What Happens Tonight (5pm)

```yaml
5_00pm:
  - you_leave: "Go to job"
  - openclaw_activates: "Autonomous mode"
  - receives: "Backlog task you sent"
  
5_15pm_8_00am:
  openclaw_works:
    - reads: "Architecture docs via memory system"
    - implements: "First capability from backlog"
    - tests: "Runs pytest"
    - commits: "To GitHub branch"
    - creates: "Draft PR"
    - sends: "Heartbeat at 7pm: 'Completed 1 feature'"
    
  repeats: "5-8 features overnight"
  
8_00am_tomorrow:
  - you_wake: "Check Telegram"
  - sees: "Heartbeat messages"
  - checks: "War Room dashboard"
  - reviews: "5 PRs on GitHub"
  - approves: "Merge good ones"
  - starts: "Your Genre work with Claude Code"
```

---

## Week 1 Expectations

```yaml
day_1_monday:
  morning: "No PRs yet (first night)"
  your_work: "Build AI Coordinator with Claude Code"
  tonight: "OpenClaw first autonomous night"
  
day_2_tuesday:
  morning: "FIRST PRS! ðŸŽ‰ (3-5 PRs)"
  your_work: "Build War Room with Claude Code"
  tonight: "OpenClaw continues"
  
day_3_7:
  pattern: "Review PRs morning, build Genre day, OpenClaw builds Adamus night"
  
end_of_week_1:
  - genre_features: "15-20 shipped"
  - adamus_capabilities: "30-40 self-implemented"
  - your_time: "63 hours (9 hrs Ã— 7 days)"
  - work_done: "168 hours (63 + 105 autonomous)"
  - multiplier: "2.67x"
```

---

## Cost Summary

```yaml
one_time:
  - embeddings: "$0.01 (to ingest docs)"
  
monthly:
  - postgres: "$0 (local)"
  - openclaw: "$0 (self-hosted)"
  - claude_api: "$100-200 (for your Genre work 8am-5pm)"
  - searxng: "$12 (optional privacy search)"
  
total: "$112-212/month"

alternative_if_tight:
  - use_ollama: "Instead of Claude API"
  - cost: "$12/month (just SearxNG)"
  - tradeoff: "Slower but still works"
```

---

## Troubleshooting

### Issue: "Can't connect to postgres"

```bash
# Check if running
pg_ctl -D /usr/local/var/postgresql@14 status

# Start if needed
brew services start postgresql@14

# Verify connection
psql -l | grep adamus_memory
```

### Issue: "OpenClaw not responding"

```bash
# Check gateway status
openclaw status

# Restart gateway
openclaw gateway restart

# Check logs
tail -f ~/.openclaw/logs/gateway.log
```

### Issue: "Memory search returns nothing"

```bash
# Re-run ingestion
cd ~/adamus
python3 src/memory/persistent_memory.py

# Verify in database
psql adamus_memory
SELECT COUNT(*) FROM document_chunks;
# Should show 2,847 chunks
```

---

## The Bottom Line

**Setup Time**: 2 hours tonight

**What You Built**:
- âœ… Adamus (ONE orchestrator with memory)
- âœ… Memory system (never forgets 76 docs)
- âœ… OpenClaw (autonomous 5pm-8am)
- âœ… Schedule (works while you job/sleep)

**What Happens**:
- Tonight 5pm: OpenClaw starts working
- Tomorrow 8am: You review first PRs
- This week: 30-40 capabilities self-implemented
- Next week: Start building Genre 10x faster

**Cost**: $112-212/month

**Status**: âœ… READY TO BUILD

**Next**: Wait until 5pm, watch OpenClaw work, review tomorrow morning ðŸš€

---

## Emergency Contacts

If anything breaks:
- OpenClaw Discord: https://discord.gg/openclaw
- GitHub Issues: https://github.com/openclaw/openclaw/issues
- Your architecture docs: ~/adamus/docs/architecture/

**You've got this. Start now.** ðŸ¦žðŸ§ 
